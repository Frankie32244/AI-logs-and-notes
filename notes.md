## 1.transformer 

* 如何通俗地理解transformer?
![098](https://github.com/Frankie32244/AI-logs-and-notes/blob/main/Pics/098.PNG))

* [illustrated-transformer-（一篇如何更好地理解transformer的blog）](https://jalammar.github.io/illustrated-transformer/)
* [paper-《Attention Is All You Need》from google brain](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
* [ Attention is All You Need浅读（简介+代码) ](https://kexue.fm/archives/4765)
* [知乎回答-如何更通俗地理解transformer](https://www.zhihu.com/question/445556653/answer/3254012065)

## 2.LLMs
* 《高级软件工程》Ppt LLms-lee ppt
> --本机路径(F:\academic-reports\2023-11-13高级软件工程汇报ppt)。

加上组会成员的一篇ppt，更加了解了大语言模型。
## 3.循环神经网络（RNN）和卷积神经网络（CNN)
3.1 RNN
* RNN:RNN 英文名 Recurrent neural networks,中文名循环神经网络，处理和预测数据上有着良好的表现，但是RNN有着提度消失和梯度爆炸的问题。所以提出了长短期记忆(LSTM)模型。RNN的主要应用是 语言建模与生成文本（本文示例重点介绍）。
[参考文章-知乎专栏-RNN详解](https://zhuanlan.zhihu.com/p/149869659)

3.2 CNN
* CNN：卷积神经网络（Convolutional Neural Networks）是一种深度学习模型或类似于人工神经网络的多层感知器，常用来分析视觉图像。
* CNN结构:
   - 数据输入层/ Input layer
   - 卷积计算层/ CONV layer
   - ReLU激励层 / ReLU layer
   - 池化层 / Pooling layer
   - 全连接层 / FC layer
* RNN是处理序列的，而CNN是用于处理二维数据的，在图像处理这一块有着出色的能力。

## 4.多模态
* 多模态:多模态指的是多种模态的信息，包括：文本、图像、视频、音频等。
* 多模态融合的作用:
多模态融合是指将来自不同感知模态（如图像、文本、语音等）的信息整合到一个统一的模型中，以更全面、准确地理解和处理数据。

## 5.多组学
* 多组学定义:多组学的关键在于综合不同层面的信息，例如将基因组、转录组和蛋白质组的数据整合在一起。这种整合可以提供更深入的生物信息，帮助科学家更全面地理解生物体系中的复杂生物学过程，如疾病的发生和发展、细胞信号传导等。多组学在生物医学研究、生物工程、医学诊断等领域中有广泛的应用。**主要应用于生物医药等方面**

## 6.什么是注意力机制
* 当我们处理一段文字或一组序列数据时，自注意力机制可以帮助模型更聪明地关注输入中不同位置的信息。这就好像我们在阅读一段文字时，有时会根据上下文关系有选择地关注不同的词语，而不是一成不变地按照顺序一个一个读下去。（我的理解就是大模型能够利用自注意力机制，做到一目十行，而且针对性地看不同的词语）。

## 7.encoder & decoder (编码器 & 解码器)
* Encoder（编码器）:
  *  特征提取： 编码器的主要任务是将输入数据转换为潜在表示（特征），捕捉输入数据中的关键信息。这通常通过一系列的神经网络层来实现，这些层可以是卷积层、循环层（对于序列数据）、全连接层等。

  * 降维： 编码器有时会包含降维的步骤，将输入数据映射到一个较低维度的表示。这有助于提取数据中的主要特征，并减少计算复杂性。

  * 非线性变换： 在编码器的每一层都会应用非线性激活函数，如ReLU（Rectified Linear Unit）等，以引入非线性特性，帮助模型学习更复杂的模式。

  * 参数学习： 编码器中的参数（权重和偏置）通过反向传播算法和优化器进行学习，以最小化编码后表示与原始输入之间的差异。

* Decoder（解码器）:
  - 特征重建： 解码器的任务是将编码后的表示转换回原始数据。这一过程通常涉及到反向的操作，即从编码中的低维表示重建出原始数据的高维表示。

  - 上采样： 如果在编码器中进行了降维操作，解码器通常会包含上采样（或反卷积）操作，以将特征图的尺寸恢复到原始输入的尺寸。

  - 非线性变换： 解码器的每一层同样应用非线性激活函数，以引入非线性特性。

  - 参数学习： 类似于编码器，解码器中的参数也通过反向传播和优化器进行学习，以最小化重建数据与原始数据之间的差异。

总体而言，编码器和解码器在深度学习中的实现通常涉及多个神经网络层、非线性激活函数和参数学习，**其目标是学习输入数据的紧凑表示，并能够有效地从该表示生成原始数据**。
![001](https://github.com/Frankie32244/AI-logs-and-notes/blob/main/Pics/001.PNG))
## 8.单细胞
单细胞生物学是生物信息学中的一个重要领域，它关注单个细胞的基因表达、蛋白质表达和其他生物学特征。传统的基因表达研究通常使用大量细胞的总体测序数据，而单细胞技术允许对单个细胞进行高通量分析。以下是单细胞领域的一些关键方面：

1、单细胞转录组学（Single-cell Transcriptomics）： 通过技术如单细胞RNA测序（scRNA-seq），研究单个细胞的基因表达水平。这有助于理解不同细胞类型的功能、发育过程、疾病状态等。

2、单细胞蛋白质组学（Single-cell Proteomics）： 通过技术如质谱和流式细胞仪，研究单个细胞的蛋白质表达水平。这有助于深入了解细胞内蛋白质的异质性和功能。

3、单细胞代谢组学（Single-cell Metabolomics）： 研究单个细胞的代谢产物，通过质谱等技术来分析单细胞的代谢活性。

4、单细胞表观基因组学（Single-cell Epigenomics）： 研究单个细胞的表观遗传修饰，如DNA甲基化和组蛋白修饰的异质性。

5、单细胞空间转录组学（Single-cell Spatial Transcriptomics）： 研究单个细胞在组织中的空间分布，以揭示不同细胞类型在组织结构中的相互作用。

6、单细胞功能基因组学（Functional Genomics at Single-cell Level）： 研究单个细胞的功能，包括基因敲除、基因编辑等实验，以深入了解单个基因在细胞水平上的作用。

单细胞技术的发展使研究者能够更详细地了解细胞群体内的异质性，揭示细胞的多样性和功能。这对于理解发育、疾病机制、个体差异等方面有着广泛的应用。在处理单细胞数据时，生物信息学方法起着至关重要的作用，帮助解释和挖掘大规模的单细胞信息。

## 9.推荐系统 
人工智能领域下的推荐系统通过分析用户行为、兴趣和偏好，提供个性化推荐。常见方法包括基于内容的推荐、协同过滤、深度学习应用以及混合推荐系统。实时推荐系统能够迅速生成实时结果，评估指标如准确率、召回率用于衡量系统性能。这些系统在电商、社交媒体等领域中为用户提供个性化体验，是人工智能应用的重要组成部分。

## 10.LSTM (长短时记忆网络)
将LSTM比作一位有记忆力的读者，他会在阅读小说时做两个主要的事情：

1、记住信息（Cell State）： 这就像读者在阅读小说时记住的主要故事情节。LSTM内部有一个称为“细胞状态（Cell State）”的结构，负责记住长期的信息。

2、选择性遗忘或更新信息（门控机制）： 这就像读者可以选择性地忽略一些不重要的细节或者更新自己对故事情节的理解。LSTM通过使用门控机制（门控遗忘、门控输入、门控输出）来决定何时遗忘、更新或输出信息。

总的来说，LSTM是一种能够更好地处理和记忆长序列信息的神经网络结构，适用于各种需要捕捉长期依赖的任务，如自然语言处理、语音识别等。

**以上，就是LSTM的内部结构。通过门控状态来控制传输状态，记住需要长时间记忆的，忘记不重要的信息；而不像普通的RNN那样只能够“呆萌”地仅有一种记忆叠加方式。对很多需要“长期记忆”的任务来说，尤其好用。**

## 11.特征点以及特征点提取
特征点:

特征点是图像或数据中的显著位置或局部区域，通常具有独特的属性，使其在图像处理和计算机视觉中用于定位、匹配和识别。这些点在图像中可能是明显的角、边缘、纹理或其他显著的结构。

常用的特征点提取算法:

1、Harris 角点检测： 通过检测图像中的角点，它对图像的旋转变化具有不变性。

2、SIFT（尺度不变特征变换）： 具有尺度和旋转不变性，通过高斯差分金字塔检测关键点，并使用局部图像梯度方向构建特征描述符。

3、SURF（加速稳健特征）： 是一种对SIFT的加速版本，使用盒状滤波进行特征点检测。

4、ORB（Oriented FAST and Rotated BRIEF）： 结合了FAST关键点检测和BRIEF特征描述符，具有较高的计算效率。

## 12.GCN  

GCN，即图卷积网络，是一种用于处理图结构数据的深度学习模型。它的主要目的是从图中学习节点之间的关系，使得神经网络能够更好地理解和利用图数据。

## 13.视图和实例

举个例子，假设我们有一个人的数据集，其中包括两个视图：一个视图包含身高和体重信息，另一个视图包含年龄和性别信息。每个人的身高、体重、年龄和性别组成了一个实例，分别属于两个不同的视图。

